{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supergruppe diskussion\n",
    "\n",
    "REVISIONS||\n",
    "---------||\n",
    "2019-0128|CEF, initial.\n",
    "2020-0295|CEF, F20 ITMAL update.\n",
    "\n",
    "## § 2 \"End-to-End Machine Learning Project\" [HOML]\n",
    "\n",
    "Genlæs kapitel (eksklusiv\"Create the Workspace\" og \"Download the Data\"), og forbered mundtlig præsentation.\n",
    "\n",
    "Lav et kort resume af de enkelte underafsnit, ca. 5 til 20 liners tekst.\n",
    "\n",
    "Husk at relater til \"The Map\":\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/F20_itmal/L03/Figs/ml_supervised_map.png\" style=\"width:400px\">\n",
    "\n",
    "Kapitler (incl. underkapitler):\n",
    "\n",
    "* Look at the Big Picture\n",
    "* Get the Data (eksklusiv Create the Workspace og Download the Data),\n",
    "* Discover and Visualize the Data to Gain Insights,\n",
    "* Prepare the Data for Machine Learning Algorithms,\n",
    "* Select and Train a Model,\n",
    "* Fine-Tune Your Model,\n",
    "* Launch, Monitor, and Maintain Your System,\n",
    "* Try It Out!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Resume: Look at the Big Picture\n",
    "\n",
    "- Appendix B, checklist for working with ML\n",
    "- Frame the problem, we can make a better model if we understand what it is to be used for, and what system it will be part of. \n",
    "- Understand the current solution, to know what to aim for with MAL solution. \n",
    "- Understand why we want ML integrated, what are we replacing or adding\n",
    "- Analyse the problem to decide model (supervised, unsupervised or reinforcement), is it a classification or regression task, learning (batch or online).\n",
    "- Select Performance Measures:\n",
    "    - For regression tasks RMSE, or MAE if there's many data outliers (calculates distance from predicted to actual values)\n",
    "- Check assumptions made so far, catch issues early on\n",
    "- This chapter is mainly related to the model selection aspect of the map\n",
    "    \n",
    "\n",
    "#### Resume: Get the Data (eksklusiv Create the Workspace og Download the Data)\n",
    "- The data's structure: Understand how the data is structured, in order to understand how to work with it. Grahps or histograms of the data is a quick way to get better understanding of the data.\n",
    "- Make sure you know if data is missing\n",
    "- Statistics of the data can be useful (.describe())\n",
    "- Looking at the feature values. Values may be preprocessed, eg. monetary value not in dollar, but in number based on dollar value (0.5 == median dollar value).\n",
    "- if there is a cap to an attribute, check with other teams if its gonna be a problem\n",
    "    - if it is, then you can either\n",
    "    - remove the data that exceeds the cap from the training set and also test set\n",
    "    - collect labels for the data that gets to the cap of an attribute\n",
    "- Create a test data set. 20% of the data. Make sure that it always stays consistently that the same data is used for testing, otherwise the model will over time learn the test data too.\n",
    "- Make sure that the data is representative, for what we wan't the model to do. Random data may be biased.\n",
    "- This chapter is mainly related to the data preprocessing and train-test split of the map.\n",
    "\n",
    "#### Resume: Discover and Visualize the Data to Gain Insights\n",
    "- Use different graphs to try visualizing the data in a way that give you insights of the data.\n",
    "- Remember to make copies of the original set, and the test set\n",
    "- Looking for correlations: Making a correlation matrix and scatter diagrams between features, to gain better understanding of the data, and even spot issues in the data and datapoint to remove from the set.\n",
    "- Data can be unuseful by itself, but you can combine stuff to give a clearer picture\n",
    "- This chapter is mainly related to the preprocessing of the map.\n",
    "\n",
    "#### Resume: Prepare the Data for Machine Learning Algorithms\n",
    "- Data preparation and cleaning should not be done manually, but by methods, so data can be easily manipulated, and reused.\n",
    "- Missing features: most models don't work well with datapoints that miss feature data. Solutions:\n",
    "    - Remove data point\n",
    "    - Remove feature, if too many data points is missing\n",
    "    - Set the feature value in data points missing the value, with something reasonable, eg mean\n",
    "- Text and Categories inside features: Should be converted to numbers, that the ML algorithms can work with\n",
    "    Ordered catogories: can go from eg 1 to 5\n",
    "    Unordered catories: can use the one-hot method, to put a 1 on the category that counts for the data points feature, and 0 for the categories that don't count in the feature for the data point.\n",
    "- ML Algorithms has problems dealing with it when the input features has big differences in scaling, eg. one feature value goes from 0-15, and another goes from 100-50000, can be fixed by scaling the values to go from 0-1.\n",
    "    - min-max-scaling\n",
    "    - Standardization\n",
    "- Data Transformation should be done as part of a transformation pipeline, so it is easily tinkered with.\n",
    "- This relates both to the preprocessing, and train predict (from the transformation pipeline usage in fit-transform) of the map\n",
    "\n",
    "#### Resume: Select and Train a Model\n",
    "- It is easy to test the data on a model, when the data is prepared. (Pretty much all the work is done)\n",
    "- Test with different models, and compare their scoring.\n",
    "    - Cross validation scoring, with k folds, that the training data is split into.\n",
    "- When testing a model it's a good idea to save these, so you can easily find old models\n",
    "\n",
    "#### Resume: Fine-Tune Your Model\n",
    "- Once we have promising models, we should fine tune them, by changing the \"hyperparameters\" of the model.\n",
    "    - grid_search: finds the best combination of hyperparameter automatically, by trying different combination, training with different combinations, and using cross-value validation to compare the best combinations and choose the best combination of hyper-parameters.\n",
    "- Analyse the best models and understand their errors. Maybe they need other features to give better results?\n",
    "- Evaluate system/model on the test set, to see how it compares to the current solution, or to none solution.\n",
    "- Consider dropping features of little importance to the data set and model outcome/prediction.\n",
    "\n",
    "- Overfitting a model to a dataset can be a real problem, make sure it does not go overboard\n",
    "- Ensamble methods??\n",
    "\n",
    "#### Resume: Launch, Monitor, and Maintain Your System\n",
    "- Deploy to production\n",
    "- Monitor the model: have alerts if the model begin underperforming, as there might have been issues or a broken component\n",
    "    - The world changes, so model \"rottening\" happens over time, and it might need to be updated.\n",
    "    - Having people analyse the result at intervals might be useful, so too much damage isn't done.\n",
    "- Automate the process of maintaining the system\n",
    "    1. Get fresh data for training automatically\n",
    "    2. Run new fine-tuning training on the model automatically\n",
    "    3. Compare new model with old model on test data, and upgrade if new model performs better, automatically\n",
    "- Backup: Every model ever deployed, and all of the datasets.\n",
    "\n",
    "#### Resume: Try It Out!.\n",
    "- kaggle.com is nice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
